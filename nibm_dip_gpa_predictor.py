# -*- coding: utf-8 -*-
"""NIBM_Dip_GPA_Predictor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16IuITDq3MCw0nJsml8P8g5tY-M63k4ar

# Data-set Import
"""

import pandas as pd

df = pd.read_csv('https://raw.githubusercontent.com/supunsathsara/NIBM-ML-data-sets/main/output-cleaned.csv')
df

"""# Pass/Fail Predict Model

## Extracting Target and Features
In this section, we prepare our dataset for machine learning by defining our target variable (y) and feature variables (x).
"""

y = df["result"]
x = df.drop(columns=['gpa', 'result'])
y

"""## Training the Decision Tree
we train our Decision Tree classifier. Harnessing the power of the sklearn library, we split our dataset into a training set (80%) and a testing set (20%). With the wisdom of randomness (random_state=42)

"""

# Import necessary libraries
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

# Split the data into training and testing sets (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Initialize the DecisionTreeClassifier
clf = DecisionTreeClassifier(random_state=42)

# Train the classifier on the training data
clf.fit(X_train, y_train)

# Make predictions on the test data
y_pred = clf.predict(X_test)

# Calculate the accuracy score
accuracy = accuracy_score(y_test, y_pred)

print("Accuracy:", accuracy)

"""## Model Evaluation"""

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Calculate and print the accuracy score
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Generate and print the classification report
class_report = classification_report(y_test, y_pred)
print("Classification Report:\n", class_report)

# Generate and print the confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:\n", conf_matrix)

# Plot the confusion matrix as a heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues', xticklabels=['Fail', 'Pass'], yticklabels=['Fail', 'Pass'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""## Predicting using the model"""

# Load the input data into a DataFrame with feature names
feature_names = ['Introduction to Computer Science', 'Mathematics for Computing', 'Programming Fundamentals', 'Fundamentals of Electronics']
input_data = pd.DataFrame({
    'Introduction to Computer Science': [4],
    'Mathematics for Computing': [3],
    'Programming Fundamentals': [4],
    'Fundamentals of Electronics': [2]
}, columns=feature_names)

predictions = clf.predict(input_data)
predictions

"""## Summery

**Accuracy: 0.78**

> Our model correctly predicted the outcome 78% of the time. Think of it as hitting the target almost 8 out of 10 times.
Classification Report:

**Precision (for PASS): 50%**



> When our model predicts a PASS, it's correct 50% of the time. This is like saying it's a bit cautious but still gets it right sometimes.

**Recall (for PASS): 100%**

> Explanation: Out of all the actual PASS outcomes, our model captured every single one. It's like not letting any PASS slip away.

**F1-score (for PASS): 67%**

> Combining precision and recall, this score indicates overall performance. Think of it as a balanced measure, striving for precision and not missing out on PASS outcomes.

**Weighted Average F1-score: 80%**

> Taking into account both PASS and FAIL, the model shows an overall balanced performance with an 80% score. It's like maintaining a good balance in accuracy across different outcomes.

In simpler terms, our model is pretty good at catching PASS instances but may need a bit more confidence in its predictions. Overall, it's doing well with an 80% balanced performance.

# GPA Predict Model

## Extracting Target and Features
In this section, we prepare our dataset for machine learning by defining our target variable (y) and feature variables (x).
"""

yr = df['gpa']
Xr = df.drop(columns=['gpa', 'result'])

"""## Training the Model

**Splitting data into train and test sets**
"""

from sklearn.model_selection import train_test_split

Xr_train, Xr_test, yr_train, yr_test = train_test_split(Xr, yr, test_size=0.2, random_state=42)

"""**Training the model using Linear Regression**"""

from sklearn.linear_model import LinearRegression

# Initialize the Linear Regression model
regressor = LinearRegression()

# Train the model
regressor.fit(Xr_train, yr_train)

# Make predictions
predictions = regressor.predict(Xr_test)

"""## Evaluate the Model"""

# Import necessary libraries
from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score
import matplotlib.pyplot as plt

# Calculate and print RMSE
mse = mean_squared_error(yr_test, predictions)
rmse = mse ** 0.5
print("Root Mean Squared Error:", rmse)

# Calculate and print R-squared (R2) score
r2 = r2_score(yr_test, predictions)
print("R-squared (R2) Score:", r2)

# Calculate and print Explained Variance Score
explained_variance = explained_variance_score(yr_test, predictions)
print("Explained Variance Score:", explained_variance)

print()
print()
# Plot predicted vs actual values with a line representing perfect alignment
plt.figure(figsize=(8, 6))
plt.scatter(yr_test, predictions, alpha=0.7, label='Predicted vs Actual GPA')
plt.plot([min(yr_test), max(yr_test)], [min(yr_test), max(yr_test)], color='red', linestyle='--', linewidth=2, label='Perfect Alignment')
plt.title('Predicted vs Actual GPA')
plt.xlabel('Actual GPA')
plt.ylabel('Predicted GPA')
plt.legend()
plt.show()

"""## Predicting the GPA using the model"""

# Sample test data for prediction
test_data = pd.DataFrame({
    'Introduction to Computer Science': [3],
    'Mathematics for Computing': [4.3],
    'Programming Fundamentals': [2],
    'Fundamentals of Electronics': [3]
})

# Use the trained regression model to make predictions
predicted_gpa = regressor.predict(test_data)

print("Predicted GPA:", predicted_gpa[0])